{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('lemm123gramsHealthWellness.csv', encoding='unicode_escape')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 52614)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>X058</th>\n",
       "      <th>X058.078</th>\n",
       "      <th>X058.078.098</th>\n",
       "      <th>X078</th>\n",
       "      <th>X078.098</th>\n",
       "      <th>X078.098.shaker</th>\n",
       "      <th>X098</th>\n",
       "      <th>X098.shaker</th>\n",
       "      <th>X098.shaker.depending</th>\n",
       "      <th>...</th>\n",
       "      <th>zero.star.option</th>\n",
       "      <th>zero.star.somehow</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zipped.chair</th>\n",
       "      <th>zipped.chair.stripped</th>\n",
       "      <th>zipped.didnt</th>\n",
       "      <th>zipped.didnt.see</th>\n",
       "      <th>zumba</th>\n",
       "      <th>zumba.qi</th>\n",
       "      <th>zumba.qi.gong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  X058  X058.078  X058.078.098  X078  X078.098  X078.098.shaker  \\\n",
       "0       1     0         0             0     0         0                0   \n",
       "1       1     0         0             0     0         0                0   \n",
       "2       5     0         0             0     0         0                0   \n",
       "3       1     0         0             0     0         0                0   \n",
       "4       4     0         0             0     0         0                0   \n",
       "\n",
       "   X098  X098.shaker  X098.shaker.depending  ...  zero.star.option  \\\n",
       "0     0            0                      0  ...                 0   \n",
       "1     0            0                      0  ...                 0   \n",
       "2     0            0                      0  ...                 0   \n",
       "3     0            0                      0  ...                 0   \n",
       "4     0            0                      0  ...                 0   \n",
       "\n",
       "   zero.star.somehow  zipped  zipped.chair  zipped.chair.stripped  \\\n",
       "0                  0       0             0                      0   \n",
       "1                  0       0             0                      0   \n",
       "2                  0       0             0                      0   \n",
       "3                  0       0             0                      0   \n",
       "4                  0       0             0                      0   \n",
       "\n",
       "   zipped.didnt  zipped.didnt.see  zumba  zumba.qi  zumba.qi.gong  \n",
       "0             0                 0      0         0              0  \n",
       "1             0                 0      0         0              0  \n",
       "2             0                 0      0         0              0  \n",
       "3             0                 0      0         0              0  \n",
       "4             0                 0      0         0              0  \n",
       "\n",
       "[5 rows x 52614 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "data0 = data.reindex(np.random.permutation(data.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data0.iloc[:,3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 52611)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=data0.iloc[:,0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 3 2 1]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(target['Rating'].unique())\n",
    "print(len(target['Rating'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 52611) (614, 1)\n"
     ]
    }
   ],
   "source": [
    "mean_vals = np.mean(data1, axis=0)\n",
    "std_val = np.std(data1)\n",
    "\n",
    "data1_centered = (data1 - mean_vals)/std_val\n",
    "\n",
    "print(data1_centered.shape, target.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     X058.078.098  X078  X078.098  X078.098.shaker  X098  X098.shaker  \\\n",
      "583             0     0         0                0     0            0   \n",
      "11              0     0         0                0     0            0   \n",
      "443             0     0         0                0     0            0   \n",
      "442             0     0         0                0     0            0   \n",
      "267             0     0         0                0     0            0   \n",
      "\n",
      "     X098.shaker.depending  X10  X10.copay  X10.copay.kaiser  ...  \\\n",
      "583                      0    0          0                 0  ...   \n",
      "11                       0    0          0                 0  ...   \n",
      "443                      0    0          0                 0  ...   \n",
      "442                      0    0          0                 0  ...   \n",
      "267                      0    0          0                 0  ...   \n",
      "\n",
      "     zero.star.option  zero.star.somehow  zipped  zipped.chair  \\\n",
      "583                 0                  0       0             0   \n",
      "11                  0                  0       0             0   \n",
      "443                 0                  0       0             0   \n",
      "442                 0                  0       0             0   \n",
      "267                 0                  0       0             0   \n",
      "\n",
      "     zipped.chair.stripped  zipped.didnt  zipped.didnt.see  zumba  zumba.qi  \\\n",
      "583                      0             0                 0      0         0   \n",
      "11                       0             0                 0      0         0   \n",
      "443                      0             0                 0      0         0   \n",
      "442                      0             0                 0      0         0   \n",
      "267                      0             0                 0      0         0   \n",
      "\n",
      "     zumba.qi.gong  \n",
      "583              0  \n",
      "11               0  \n",
      "443              0  \n",
      "442              0  \n",
      "267              0  \n",
      "\n",
      "[5 rows x 52611 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rating\n",
      "583       5\n",
      "11        4\n",
      "443       5\n",
      "442       3\n",
      "267       4\n"
     ]
    }
   ],
   "source": [
    "print(target.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping = {label: idx for idx, label in enumerate(np.unique(target['Rating']))}\n",
    "class_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m\\Anaconda2\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\m\\Anaconda2\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>OH_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>583</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rating  OH_rating\n",
       "583       5          4\n",
       "11        4          3\n",
       "443       5          4\n",
       "442       3          2\n",
       "267       4          3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['OH_rating']=target['Rating']\n",
    "target['OH_rating'] = target['Rating'].map(class_mapping)\n",
    "target.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583    4\n",
       "11     3\n",
       "443    4\n",
       "442    2\n",
       "267    3\n",
       "Name: OH_rating, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target1 = target['OH_rating']\n",
    "target1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491, 52611)\n",
      "(491,)\n",
      "(123, 52611)\n",
      "(123,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data1[:491]\n",
    "X_test = data1[491:]\n",
    "y_train = target1[:491]\n",
    "y_test = target1[491:]\n",
    "\n",
    "################################\n",
    "# for adding the names of the classes after prediction from earlier in script\n",
    "y_trainNames = target['Rating']\n",
    "y_trainNames = y_trainNames[:491]\n",
    "y_trainNames.columns=['Rating']\n",
    "y_trainNames1=pd.DataFrame(y_trainNames)\n",
    "\n",
    "y_testNames = target['Rating']\n",
    "y_testNames = y_testNames[491:]\n",
    "y_testNames.columns=['Rating']\n",
    "y_testNames1=pd.DataFrame(y_testNames)\n",
    "################################\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583    4\n",
       "11     3\n",
       "443    4\n",
       "442    2\n",
       "267    3\n",
       "      ..\n",
       "319    4\n",
       "364    4\n",
       "412    4\n",
       "141    4\n",
       "454    3\n",
       "Name: OH_rating, Length: 491, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.keras as keras\n",
    "#optionally use import tensorflow.keras as keras when no longer experimental contributor package development\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0508 09:38:25.181593  6864 deprecation.py:506] From C:\\Users\\m\\Anaconda2\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model6 = keras.models.Sequential()\n",
    "\n",
    "model6.add(\n",
    "    keras.layers.Dense(\n",
    "        units=20000,   #output units need to match next layer inputs \n",
    "        input_dim=52611, #number of features for input above says 52611\n",
    "        kernel_initializer='glorot_uniform',# name of the guy behind Xavier Initialization; the biases to zero\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model6.add(\n",
    "    keras.layers.Dense(\n",
    "        units=10000,   #output matches next layer input \n",
    "        input_dim=20000, #input matches last layer's output\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model6.add(\n",
    "    keras.layers.Dense(\n",
    "        units=5000,   #output matches next layer input \n",
    "        input_dim=10000, #input matches last layer's output\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "\n",
    "model6.add(\n",
    "    keras.layers.Dense(\n",
    "        units=900,   #output matches next layer input \n",
    "        input_dim=5000, #input matches last layer's output\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "\n",
    "model6.add(\n",
    "    keras.layers.Dense(\n",
    "        units=300,   #output matches next layer input \n",
    "        input_dim=900, #input matches last layer's output\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "\n",
    "model6.add(\n",
    "    keras.layers.Dense(\n",
    "        units=200,   #output matches next layer input \n",
    "        input_dim=300, #input matches last layer's output\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "\n",
    "\n",
    "model6.add(\n",
    "    keras.layers.Dense(\n",
    "        units=100,   #output matches next layer input \n",
    "        input_dim=200, #input matches last layer's output\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model6.add(\n",
    "    keras.layers.Dense(\n",
    "        units=100,   #output matches next layer input \n",
    "        input_dim=100, #input matches last layer's output\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "\n",
    "model6.add(\n",
    "    keras.layers.Dense(\n",
    "        units=100,   #output matches next layer input \n",
    "        input_dim=100, #input matches last layer's output\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='relu'))\n",
    "\n",
    "\n",
    "model6.add(\n",
    "    keras.layers.Dense(\n",
    "        units=5,  #these are the number of class categories in our target  \n",
    "        input_dim=100,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='softmax'))#will return the class membership probs summing to 1 of all class probs\n",
    "\n",
    "# these are hyperparameters that can be tuned if overfitting during training, or to get better accuracy\n",
    "sgd_optimizer = keras.optimizers.SGD( \n",
    "        lr=0.001, decay=1e-7, momentum=.9)\n",
    "\n",
    "# categorical_crossentropy is used in multiclass classification instead of binary_crossentropy\n",
    "# to match the softmax function\n",
    "model6.compile(optimizer=sgd_optimizer,\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "# it was 'categorical_crossentropy', but that expects binary matrices of 1s and 0s\n",
    "# it said to use sparse_categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 417 samples, validate on 74 samples\n",
      "417/417 [==============================] - 10200s 24s/sample - loss: 1.6134 - val_loss: 1.5150\n",
      "1588955915.8353844 1588966119.2862213 10203.450836896896\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "\n",
    "history6 = model6.fit(X_train, y_train,\n",
    "                    batch_size=90, epochs=1,\n",
    "                    verbose=1, \n",
    "                    validation_split=0.15) \n",
    "end=time.time()\n",
    "fit_time=(end-start)\n",
    "print(start,end,fit_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.05"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10203/60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above DNN with only 1 iteration took 170 minutes or 2 1/2 hours to run. \n",
    "We can test all of these variations later, when we set up GPUs for tensorflow \n",
    "either in a new cheap laptop equipped with the GPU or on Google Engine Cloud. \n",
    "Since my laptops don't have the Thunderbolt 3 port, they cannot have the external GPU hardware added, \n",
    "which by the way, is almost as much as getting a [Lenovo](https://www.bestbuy.com/site/hp-15-6-gaming-laptop-amd-ryzen-5-8gb-memory-nvidia-geforce-gtx-1050-256gb-solid-state-drive-shadow-black/6364574.p?skuId=6364574#tab=buyingOptions?bof=openbox) with the NVIDIA GPU at Best Buy at the time of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 predictions:  [4 4 4]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred6 = model6.predict_classes(X_train, verbose=0)\n",
    "print('First 3 predictions: ', y_train_pred6[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made it 5 classes for ratings 0-4 as the output layer. In the first script Copy5a,\n",
    "I didn't  correct the 19 class outputs and it tried classifying with 20-23% accuracy on train and test sets. \n",
    "This didn't happen in any of the other class categories, surprisingly, because none of the training set \n",
    "had those classes to fit to when predicting on the training set. This could be that there are \n",
    "now 10,000 more units in the first \n",
    "few hidden layers that are compensated for when outputting the predicted class in the final layer of \n",
    "output using softmax logistic regression that returns class membership probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred6 = model6.predict_classes(X_train, \n",
    "                                     verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     OH_Rating  Rating  predicted\n",
      "583          4       5          4\n",
      "11           3       4          4\n",
      "443          4       5          4\n",
      "442          2       3          3\n",
      "267          3       4          0\n",
      "..         ...     ...        ...\n",
      "319          4       5          4\n",
      "364          4       5          0\n",
      "412          4       5          0\n",
      "141          4       5          4\n",
      "454          3       4          4\n",
      "\n",
      "[491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred6 = pd.DataFrame(y_train_pred6)\n",
    "y_train_pred6.columns=['predicted']\n",
    "\n",
    "y_train6 = y_train\n",
    "y_train6 = pd.DataFrame(y_train6)\n",
    "y_train6.columns=['OH_Rating']\n",
    "\n",
    "y_train_pred6.index=y_train6.index\n",
    "\n",
    "Train6=pd.concat([y_train6['OH_Rating'],y_trainNames1['Rating'],y_train_pred6['predicted']],axis=1)\n",
    "\n",
    "print(Train6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred6 = model6.predict_classes(X_test, \n",
    "                                    verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     OH_Rating  Rating  predicted\n",
      "88           2       3          4\n",
      "502          1       2          2\n",
      "581          4       5          4\n",
      "307          3       4          3\n",
      "300          3       4          0\n",
      "..         ...     ...        ...\n",
      "98           2       3          4\n",
      "322          4       5          4\n",
      "382          3       4          4\n",
      "365          4       5          4\n",
      "510          4       5          4\n",
      "\n",
      "[123 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred6 = pd.DataFrame(y_test_pred6)\n",
    "y_test_pred6.columns=['predicted']\n",
    "\n",
    "y_test6 = y_test\n",
    "y_test6 = pd.DataFrame(y_test6)\n",
    "y_test6.columns=['OH_Rating']\n",
    "\n",
    "y_test_pred6.index=y_test6.index\n",
    "\n",
    "Test6=pd.concat([y_test6['OH_Rating'],y_testNames1['Rating'],y_test_pred6['predicted']],axis=1)\n",
    "\n",
    "print(Test6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Correctly Predicted: 255 Training Accuracy: 0.5193482688391039 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = sum(Train6['OH_Rating']==Train6['predicted'])\n",
    "l = len(Train6['Rating'])\n",
    "accTrain6 = s/l\n",
    "print('Training Correctly Predicted:',s,'Training Accuracy:',accTrain6,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Correctly Predicted: 54 Testing Accuracy: 0.43902439024390244\n"
     ]
    }
   ],
   "source": [
    "s = sum(Test6['OH_Rating']==Test6['predicted'])\n",
    "l = len(Test6['OH_Rating'])\n",
    "accTest6 = s/l\n",
    "print('Testing Correctly Predicted:',s,'Testing Accuracy:',accTest6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DNN with more hidden layers and more units in the first few hidden layers, didn't score better than the \n",
    "other DNNs with half as many hidden layers and far less units. This DNN actually scored worse, and took 5-20 times as long.\n",
    "This could be because of the tanh activation, but the relu takes much longer, also this DNN was only trained on 1 iteration\n",
    "instead of 20-60 epochs as the faster DNNs had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
